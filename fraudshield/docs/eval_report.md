# FraudShield Evaluation Report

**Model Version:** `xgb_v0.3.1`  
**Evaluation Date:** 2025-12-15  
**Dataset:** Synthetic fraud transactions (50K samples, 2.3% fraud rate)  
**Eval Harness:** `src/evaluation/eval_harness.py`

---

## Executive Summary

| Metric | Value | Target | Status |
|--------|-------|--------|--------|
| PR-AUC (overall) | 0.847 | ≥ 0.80 | ✅ Pass |
| ROC-AUC | 0.91 | — | ℹ️ Info only |
| Precision @ 0.5 threshold | 0.82 | ≥ 0.75 | ✅ Pass |
| Recall @ 0.5 threshold | 0.71 | ≥ 0.65 | ✅ Pass |
| p95 Latency | ~45ms | < 50ms | ✅ Pass |

**Primary metric:** PR-AUC (handles class imbalance better than ROC-AUC)

---

## Slice Analysis

Performance across defined subgroups. CI gate requires all slices ≥ 0.75 PR-AUC.

| Slice | N | Fraud % | PR-AUC | Status |
|-------|---|---------|--------|--------|
| Overall | 50,000 | 2.3% | 0.847 | ✅ Pass |
| High-value (>$500) | 8,200 | 4.1% | 0.88 | ✅ Pass |
| New users (<30d) | 6,100 | 3.8% | 0.79 | ✅ Pass |
| Mobile channel | 18,500 | 2.1% | 0.83 | ✅ Pass |
| Card-not-present | 12,300 | 3.2% | 0.86 | ✅ Pass |
| International | 4,200 | 5.6% | 0.81 | ✅ Pass |
| Repeat offenders | 890 | 12.4% | 0.92 | ✅ Pass |

### Worst Performing Slice

**New users (<30d):** PR-AUC = 0.79

This is expected—new users have limited transaction history for behavioral features. The model relies more heavily on transaction-level signals for this cohort.

**Mitigation:** Enhanced velocity features for new users, stricter thresholds during first 30 days.

---

## Calibration

Expected Calibration Error (ECE) measures how well predicted probabilities match actual outcomes.

| Bin | Predicted | Actual | Gap |
|-----|-----------|--------|-----|
| 0.0-0.1 | 0.05 | 0.04 | 0.01 |
| 0.1-0.2 | 0.15 | 0.14 | 0.01 |
| 0.2-0.3 | 0.25 | 0.27 | 0.02 |
| 0.3-0.4 | 0.35 | 0.33 | 0.02 |
| 0.4-0.5 | 0.45 | 0.48 | 0.03 |
| 0.5-0.6 | 0.55 | 0.52 | 0.03 |
| 0.6-0.7 | 0.65 | 0.68 | 0.03 |
| 0.7-0.8 | 0.75 | 0.73 | 0.02 |
| 0.8-0.9 | 0.85 | 0.87 | 0.02 |
| 0.9-1.0 | 0.95 | 0.93 | 0.02 |

**ECE = 0.021** (Target: < 0.05) ✅ Pass

---

## Threshold Analysis

Decision thresholds for the three-bucket system:

| Decision | Threshold | Precision | Recall | Volume % |
|----------|-----------|-----------|--------|----------|
| Block | ≥ 0.85 | 0.94 | 0.31 | 2.1% |
| Review | 0.45–0.85 | 0.67 | 0.52 | 8.3% |
| Allow | < 0.45 | — | — | 89.6% |

**Estimated manual review load:** ~8.3% of transactions  
**Estimated auto-block rate:** ~2.1% of transactions

---

## Feature Importance (Top 10)

| Rank | Feature | Importance | Type |
|------|---------|------------|------|
| 1 | `velocity_user_1h` | 0.142 | Behavioral |
| 2 | `amount_zscore` | 0.098 | Transaction |
| 3 | `time_since_last_txn` | 0.087 | Behavioral |
| 4 | `merchant_risk_score` | 0.076 | Enrichment |
| 5 | `device_age_days` | 0.065 | Device |
| 6 | `channel_risk` | 0.058 | Transaction |
| 7 | `user_avg_amount_ratio` | 0.054 | Behavioral |
| 8 | `hour_of_day_risk` | 0.048 | Temporal |
| 9 | `geo_distance_from_usual` | 0.044 | Location |
| 10 | `merchant_category_embed_0` | 0.039 | Embedding |

---

## Regression Tests

Comparison against previous model version (`xgb_v0.3.0`):

| Metric | v0.3.0 | v0.3.1 | Delta | Status |
|--------|--------|--------|-------|--------|
| PR-AUC | 0.839 | 0.847 | +0.8% | ✅ Improved |
| New users slice | 0.76 | 0.79 | +3.0% | ✅ Improved |
| High-value slice | 0.87 | 0.88 | +1.0% | ✅ Improved |
| Latency p95 | 42ms | 45ms | +3ms | ✅ Within tolerance |

**Regression threshold:** No slice may drop > 5% from previous version.  
**Result:** All slices improved or held steady. ✅

---

## CI Gate Summary

```yaml
# .github/workflows/eval-gate.yml
eval_gates:
  pr_auc_overall: 0.80
  pr_auc_per_slice: 0.75
  regression_tolerance: 0.05
  ece_max: 0.05
  latency_p95_ms: 50
```

| Gate | Threshold | Actual | Status |
|------|-----------|--------|--------|
| PR-AUC overall | ≥ 0.80 | 0.847 | ✅ |
| PR-AUC all slices | ≥ 0.75 | min 0.79 | ✅ |
| No regression > 5% | — | max +3% | ✅ |
| ECE | < 0.05 | 0.021 | ✅ |
| Latency p95 | < 50ms | 45ms | ✅ |

**Overall: ✅ PASS**

---

## How to Reproduce

```bash
cd fraudshield
make eval                    # Full evaluation suite
make eval-slice              # Slice analysis only
make eval-calibration        # Calibration report
python -m src.evaluation.eval_harness --model models/xgb_v0.3.1.pkl
```

---

## Appendix: Methodology Notes

1. **Train/test split:** Time-based (train: 2024-01 to 2024-10, test: 2024-11 to 2024-12)
2. **Label definition:** Transaction flagged as fraud within 90-day chargeback window
3. **Synthetic data:** Generated using realistic patterns; no real PII
4. **Confidence intervals:** Bootstrap with 1000 iterations (not shown in summary)

---

*Generated by `eval_harness.py` | Commit: a1b2c3d4*
